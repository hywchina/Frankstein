{"instruction": "Create a short, concise summary of the paper based on its abstract.\n\nFew-shot learning (FSL) is one of the key future steps in machine learning and raises a lot of attention. In this paper, we focus on the FSL problem of dialogue understanding, which contains two closely related tasks: intent detection and slot filling. Dialogue understanding has been proven to benefit a lot from jointly learning the two sub-tasks. However, such joint learning becomes challenging in the few-shot scenarios: on the one hand, the sparsity of samples greatly magnifies the difficulty of modeling the connection between the two tasks; on the other hand, how to jointly learn multiple tasks in the few-shot setting is still less investigated. In response to this, we introduce FewJoint, the first FSL benchmark for joint dialogue understanding. FewJoint provides a new corpus with 59 different dialogue domains from real industrial API and a code platform to ease FSL experiment set-up, which are expected to advance the research of this field. Further, we find that insufficient performance of the few-shot setting often leads to noisy sharing between two sub-task and disturbs joint learning. To tackle this, we guide slot with explicit intent information and propose a novel trust gating mechanism that blocks low-confidence intent information to ensure high quality sharing. Besides, we introduce a Reptile-based meta-learning strategy to achieve better generalization in unseen few-shot domains. In the experiments, the proposed method brings significant improvements on two datasets and achieve new state-of-the-art performance.", "output": "This paper introduces FewJoint, the first few-shot learning (FSL) benchmark for joint dialogue understanding. It addresses the challenges in few-shot scenarios, where the sparsity of samples makes it difficult to model the connection between two tasks. The paper also explores the less-investigated area of jointly learning multiple tasks in the few-shot setting.\n\nThe paper identifies that the insufficient performance in few-shot settings often leads to noisy sharing between the two sub-tasks, disturbing joint learning. To tackle this, the authors propose using explicit intent information and a novel trust gating mechanism that blocks low-confidence intent information.\n\nThe paper also introduces a Reptile-based meta-learning strategy to improve generalization in unseen few-shot domains. This strategy allows the model to learn more generalizable features from the few examples, leading to better performance on unseen tasks.\n\nThe proposed method is tested on two datasets and achieves significant improvements and new state-of-the-art performance. Overall, the paper contributes to the advancement of few-shot learning for joint dialogue understanding and provides a new benchmark and strategies for future research in this field.", "generator": "./save_merge_models/instruct_math/instruct/task_arithmetic_scaling_coefficient_1.0", "dataset": "selfinstruct"}
